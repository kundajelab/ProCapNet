{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6f543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import logomaker\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../2_train_models\")\n",
    "\n",
    "from file_configs import FoldFilesConfig, MergedFilesConfig\n",
    "from data_loading import extract_peaks, extract_observed_profiles\n",
    "from performance_metrics import compute_performance_metrics\n",
    "from common_functions import load_coords\n",
    "from common_functions import get_orientation_indexes, get_norm_shannon_entropies\n",
    "from load_annotations_utils import find_peak_overlap_labels, get_ccre_bed, find_peak_overlap\n",
    "from load_annotations_utils import load_coords_with_summits, get_gene_region_overlap, get_dist_to_TSS\n",
    "from motif_hits_utils import load_motif_hits\n",
    "\n",
    "from plot_utils import get_continuous_cmap\n",
    "from plot_utils import jitter_dots, plot_scatter_and_boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be76ec8",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7141b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify what set of models to look at\n",
    "cell_type = \"K562\"\n",
    "\n",
    "# the unique IDs for each of the folds / models in this cell type\n",
    "timestamps = [\"2023-05-29_15-51-40\",\n",
    "              \"2023-05-29_15-58-41\",\n",
    "              \"2023-05-29_15-59-09\",\n",
    "              \"2023-05-30_01-40-06\",\n",
    "              \"2023-05-29_23-21-23\",\n",
    "              \"2023-05-29_23-23-45\",\n",
    "              \"2023-05-29_23-24-11\"]\n",
    "\n",
    "# these usually don't change\n",
    "model_type = \"strand_merged_umap\"\n",
    "data_type = \"procap\"\n",
    "\n",
    "# size of the model inputs and outputs\n",
    "in_window = 2114\n",
    "out_window = 1000\n",
    "\n",
    "# motif names below are specific to the K562 profile modisco run\n",
    "motif_names = [\"BRE/SP\", \"CA-Inr\", \"ETS\", \"NFY\", \"NRF1\", \"ATF1\", \"TATA\",\n",
    "               \"THAP11\", \"YY1\", \"AP1\", \"TA-Inr\", \"CTCF\", \"ZBTB33\", \"TCT\", \"TATATA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ed7d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 2023-05-29_15-51-40\n",
      "Timestamp: 2023-05-29_15-58-41\n",
      "Timestamp: 2023-05-29_15-59-09\n",
      "Timestamp: 2023-05-30_01-40-06\n",
      "Timestamp: 2023-05-29_23-21-23\n",
      "Timestamp: 2023-05-29_23-23-45\n",
      "Timestamp: 2023-05-29_23-24-11\n"
     ]
    }
   ],
   "source": [
    "# Load the config objects (filepaths holders) for each fold a model was trained on\n",
    "\n",
    "def load_fold_configs(cell_type, timestamps,\n",
    "                      model_type = model_type, data_type = data_type):\n",
    "\n",
    "    fold_configs = []\n",
    "    for fold_i, timestamp in enumerate(timestamps):\n",
    "        # folds are 1-indexed, and config constructor is expecting a string\n",
    "        fold = str(fold_i + 1)\n",
    "        \n",
    "        # load the config object for this specific fold / model\n",
    "        config = FoldFilesConfig(cell_type, model_type, fold, timestamp, data_type)\n",
    "        fold_configs.append(config)\n",
    "        \n",
    "    return fold_configs\n",
    "\n",
    "fold_configs = load_fold_configs(cell_type, timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9910a215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config object for when model outputs were merged across all folds\n",
    "\n",
    "merged_config = MergedFilesConfig(cell_type, model_type, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eca17cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these paths aren't specific to any model / fold, cell type, or data_type\n",
    "\n",
    "proj_dir = merged_config.proj_dir\n",
    "\n",
    "figures_dir = proj_dir + \"figures/\"\n",
    "os.makedirs(figures_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c77b6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pseudorep_filepaths(pseudorep, pos_or_neg, data_dir):\n",
    "    # Get paths to bigwigs for the pseudoreplicates of an experiment\n",
    "    #  - pseudorep should be either an int (1-indexed) or an integer string\n",
    "    \n",
    "    assert pos_or_neg in [\"pos\", \"neg\"], pos_or_neg\n",
    "    return os.path.join(data_dir, \"pseudorep\" + str(pseudorep) + \".\" + pos_or_neg + \".bigWig\")\n",
    "\n",
    "\n",
    "def load_pseudoreplicate_profiles(pseudorep, peaks_path, data_dir, out_window=out_window):\n",
    "    pos_bw_path = get_pseudorep_filepaths(pseudorep, \"pos\", data_dir)\n",
    "    neg_bw_path = get_pseudorep_filepaths(pseudorep, \"neg\", data_dir)\n",
    "    \n",
    "    profs = extract_observed_profiles(pos_bw_path, neg_bw_path, peaks_path,\n",
    "                                      out_window=out_window, verbose=True)\n",
    "    return profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a81a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replicate_filepaths(rep, pos_or_neg, data_dir):\n",
    "    # Get paths to bigwigs for the replicates of an experiment\n",
    "    #  - rep should be either an int (1-indexed) or an integer string\n",
    "    \n",
    "    assert pos_or_neg in [\"pos\", \"neg\"], pos_or_neg\n",
    "    return os.path.join(data_dir, \"rep\" + str(rep) + \".5prime.\" + pos_or_neg + \".bigWig\")\n",
    "\n",
    "\n",
    "def load_replicate_profiles(rep, peaks_path, data_dir, out_window=out_window):\n",
    "    pos_bw_path = get_replicate_filepaths(rep, \"pos\", data_dir)\n",
    "    neg_bw_path = get_replicate_filepaths(rep, \"neg\", data_dir)\n",
    "    \n",
    "    profs = extract_observed_profiles(pos_bw_path, neg_bw_path, peaks_path,\n",
    "                                      out_window=out_window, verbose=True)\n",
    "    return profs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427ebbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coords = load_coords_with_summits(merged_config.all_peak_path, in_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef44632d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Profiles: 4334it [00:01, 3957.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold1_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Profiles: 4334it [00:01, 4142.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold1_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4334it [00:01, 4194.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold1_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4334it [00:01, 3541.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold1_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4334it [00:01, 3030.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold1_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3699it [00:00, 4713.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold2_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3699it [00:00, 4751.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold2_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3699it [00:00, 4793.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold2_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3699it [00:00, 4363.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold2_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3699it [00:01, 3634.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold2_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4559it [00:00, 4724.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold3_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4559it [00:00, 4780.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold3_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4559it [00:00, 4801.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold3_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4559it [00:00, 4698.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold3_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4559it [00:01, 4045.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold3_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3887it [00:00, 4647.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold4_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3887it [00:00, 4769.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold4_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3887it [00:00, 4779.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold4_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3887it [00:00, 4557.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold4_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 3887it [00:00, 3914.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold4_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 3887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4470it [00:00, 4711.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold5_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4470it [00:00, 4783.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold5_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4470it [00:00, 4764.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold5_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4470it [00:00, 4694.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold5_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4470it [00:01, 3960.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold5_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 5238it [00:01, 4702.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold6_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 5238it [00:01, 4791.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold6_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Profiles: 5238it [00:01, 4782.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold6_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Profiles: 5238it [00:01, 4671.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold6_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 5238it [00:01, 4038.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold6_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Profiles: 4347it [00:00, 4747.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold7_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4347it [00:00, 4821.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold7_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Profiles: 4347it [00:00, 4827.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold7_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Profiles: 4347it [00:00, 4750.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold7_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Profiles: 4347it [00:01, 4267.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== In Extract Profiles ==\n",
      "Peak filepath: /mnt/lab_data2/kcochran/procapnet/data/procap/processed/K562/peaks_fold7_test.bed.gz\n",
      "Profile length: 1000\n",
      "Num. Examples: 4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_sort_order_test_sets(merged_config, fold_configs, in_window=in_window):\n",
    "    # Each model / fold has a mutually exclusive test set; the order of the examples\n",
    "    # in each test set differs from the order in the merged file of all examples.\n",
    "    # So, this function figures out how to reorder the test set model predictions\n",
    "    # so that they can be compared to the observed data.\n",
    "    \n",
    "    # First, load in the test set coordinates for each fold's test set\n",
    "    \n",
    "    test_coords = []\n",
    "    for config in fold_configs:\n",
    "        test_coords.extend(load_coords(config.test_peak_path, in_window))\n",
    "        \n",
    "    # Second, load in the test set coordinates for the merged file\n",
    "    # (the \"correct order\")\n",
    "    \n",
    "    all_coords = load_coords(merged_config.all_peak_path, in_window)\n",
    "    \n",
    "    # Third, figure out the re-ordering needed to arrange the test coords\n",
    "    # so they match the ordering in the merged file.\n",
    "    # (then use that ordering later to fix the order of model predictions)\n",
    "    \n",
    "    sort_order = [test_coords.index(coord) for coord in all_coords]\n",
    "    assert np.all(np.array(all_coords) == np.array(test_coords)[sort_order])\n",
    "    \n",
    "    return sort_order\n",
    "\n",
    "\n",
    "def load_test_data(merged_config, fold_configs):\n",
    "    true_profs = []\n",
    "    true_counts = []\n",
    "    pseudorep1_profs = []\n",
    "    pseudorep2_profs = []\n",
    "    rep1_profs = []\n",
    "    rep2_profs = []\n",
    "    log_pred_profs = []\n",
    "    pred_logcounts = []\n",
    "    \n",
    "    for config in fold_configs:\n",
    "        # Load observed data: replicate-merged PRO-cap signal\n",
    "        obs_profs = extract_observed_profiles(config.plus_bw_path,\n",
    "                                              config.minus_bw_path,\n",
    "                                              config.test_peak_path,\n",
    "                                              out_window=out_window,\n",
    "                                              verbose=True)\n",
    "        true_profs.extend(obs_profs)\n",
    "        true_counts.extend(obs_profs.sum(axis=-1).squeeze())\n",
    "\n",
    "        # Load PRO-cap signal for each pseudoreplicate individually (to see reproducibility)\n",
    "        pseudorep1_profs.extend(load_pseudoreplicate_profiles(1, config.test_peak_path, config.data_dir))\n",
    "        pseudorep2_profs.extend(load_pseudoreplicate_profiles(2, config.test_peak_path, config.data_dir))\n",
    "        \n",
    "        # Load PRO-cap signal for each replicate individually (also to see reproducibility)\n",
    "        rep1_profs.extend(load_replicate_profiles(1, config.test_peak_path, config.data_dir))\n",
    "        rep2_profs.extend(load_replicate_profiles(2, config.test_peak_path, config.data_dir))\n",
    "\n",
    "        # Load model predictions\n",
    "        log_pred_profs.extend(np.load(config.pred_profiles_test_path))\n",
    "        pred_logcounts.extend(np.load(config.pred_logcounts_test_path).squeeze())\n",
    "        \n",
    "        # everything above should have loaded in the same number of examples/loci\n",
    "        \n",
    "        assert len(true_profs) == len(true_counts)\n",
    "        assert len(pseudorep1_profs) == len(pseudorep2_profs)\n",
    "        assert len(rep1_profs) == len(rep2_profs)\n",
    "        assert len(pseudorep1_profs) == len(rep1_profs)\n",
    "        assert len(pseudorep1_profs) == len(true_counts)\n",
    "        assert len(log_pred_profs) == len(pred_logcounts)\n",
    "        assert len(pred_logcounts) == len(true_counts)\n",
    "        \n",
    "    sort_order = get_sort_order_test_sets(merged_config, fold_configs)\n",
    "    \n",
    "    true_profs = np.array(true_profs)[sort_order]\n",
    "    true_counts = np.array(true_counts)[sort_order]\n",
    "    pseudorep1_profs = np.array(pseudorep1_profs)[sort_order]\n",
    "    pseudorep2_profs = np.array(pseudorep2_profs)[sort_order]\n",
    "    rep1_profs = np.array(rep1_profs)[sort_order]\n",
    "    rep2_profs = np.array(rep2_profs)[sort_order]\n",
    "    log_pred_profs = np.array(log_pred_profs)[sort_order]\n",
    "    pred_logcounts = np.array(pred_logcounts)[sort_order]\n",
    "    \n",
    "    pred_profs = np.exp(log_pred_profs)\n",
    "    \n",
    "    return true_profs, true_counts, pseudorep1_profs, pseudorep2_profs, rep1_profs, rep2_profs, pred_profs, pred_logcounts\n",
    "\n",
    "\n",
    "true_profs, true_counts, pseudorep1_profs, pseudorep2_profs, rep1_profs, rep2_profs, \\\n",
    "                        pred_profs, pred_logcounts = load_test_data(merged_config, fold_configs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac752cf6",
   "metadata": {},
   "source": [
    "## Calculate + Plot Model Performance on Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stratify performance across folds, we need to label\n",
    "# each test example with which fold it was in the test set for.\n",
    "\n",
    "# Fold assignment (below) needs to match what was in\n",
    "# 1_process_data/_split_peaks_train_val_test.py\n",
    "\n",
    "FOLDS = [[\"chr1\", \"chr4\"],\n",
    "         [\"chr2\", \"chr13\", \"chr16\"],\n",
    "         [\"chr5\", \"chr6\", \"chr20\", \"chr21\"],\n",
    "         [\"chr7\", \"chr8\", \"chr9\"],\n",
    "         [\"chr10\", \"chr11\", \"chr12\"],\n",
    "         [\"chr3\", \"chr14\", \"chr15\", \"chr17\"],\n",
    "         [\"chr18\", \"chr19\", \"chr22\", \"chrX\", \"chrY\"]]\n",
    "\n",
    "def get_fold_label(chrom):\n",
    "    # returns *0-indexed* fold num that this chromosome was in the test set for\n",
    "    for fold_i, fold_chroms in enumerate(FOLDS):\n",
    "            if chrom in fold_chroms:\n",
    "                return fold_i\n",
    "    return -1\n",
    "\n",
    "def make_fold_labels(coords):\n",
    "    # Make list of len [num_peaks] / length of all_peak_path file,\n",
    "    # where entry i is the fold that example i was in the test set for.\n",
    "    \n",
    "    # coord[0] is the chromosome (first column from bed file)\n",
    "    fold_labels = [get_fold_label(coord[0]) for coord in coords]\n",
    "    \n",
    "    # check we assigned a fold for every single example/peak\n",
    "    assert all([label > -1 for label in fold_labels]), fold_labels\n",
    "    return fold_labels\n",
    "        \n",
    "    \n",
    "fold_labels = make_fold_labels(all_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90085689",
   "metadata": {},
   "source": [
    "### Counts Task Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ebb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_vs_obs_logcounts_pearson_over_folds(pred_logcounts, true_counts, fold_labels):\n",
    "    pred_logcounts = pred_logcounts.squeeze()\n",
    "    true_counts = true_counts.squeeze()\n",
    "    \n",
    "    # if the model preds/data are multi-stranded, sum across the two strands\n",
    "    if len(pred_logcounts.shape) > 1:\n",
    "        pred_logcounts = np.log(np.sum(np.exp(pred_logcounts), axis=-1))\n",
    "    if len(true_counts.shape) > 1:\n",
    "        true_counts = np.sum(true_counts, axis=-1)\n",
    "    \n",
    "    assert pred_logcounts.shape == true_counts.shape\n",
    "    \n",
    "    # assuming true counts, not log-counts\n",
    "    true_logcounts = np.log1p(true_counts)\n",
    "    \n",
    "    folds = sorted(list(set(fold_labels)))\n",
    "    \n",
    "    pearson_rs = []\n",
    "    for fold in folds:\n",
    "        # convert numeric fold labels to booleans\n",
    "        in_fold = np.array([fold_num == fold for fold_num in fold_labels])\n",
    "        \n",
    "        pred_logcounts_fold = pred_logcounts[in_fold]\n",
    "        true_logcounts_fold = true_logcounts[in_fold]\n",
    "        \n",
    "        pearson_r = np.corrcoef(pred_logcounts_fold, true_logcounts_fold)[0,1]\n",
    "        \n",
    "        pearson_rs.append(pearson_r)\n",
    "        \n",
    "    print(\"Test Set Pearson Correlations, All Folds:\")\n",
    "    print(pearson_rs)\n",
    "    \n",
    "    print(\"\\nAverage Within-Fold Test Pearson Correlation:\")\n",
    "    print(np.mean(pearson_rs))\n",
    "    \n",
    "    print(\"\\nStandard Deviation of Pearson Correlation Across Folds:\")\n",
    "    print(np.std(pearson_rs))\n",
    "    \n",
    "    \n",
    "calc_pred_vs_obs_logcounts_pearson_over_folds(pred_logcounts, true_counts, fold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25364efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_replicate_logcounts_pearson(rep1_profs, rep2_profs):\n",
    "    assert rep1_profs.shape == rep2_profs.shape and len(rep1_profs.shape) == 3\n",
    "    \n",
    "    rep1_counts = rep1_profs.sum(axis=(-1,-2))\n",
    "    rep2_counts = rep2_profs.sum(axis=(-1,-2))\n",
    "    \n",
    "    # true counts, not log-counts\n",
    "    rep1_logcounts = np.log1p(rep1_counts)\n",
    "    rep2_logcounts = np.log1p(rep2_counts)\n",
    "    \n",
    "    pearson_r = np.corrcoef(rep1_logcounts, rep2_logcounts)[0,1]\n",
    "    \n",
    "    print(\"Pearson corr. between replicates:\")\n",
    "    print(pearson_r)\n",
    "    \n",
    "    \n",
    "calc_replicate_logcounts_pearson(rep1_profs, rep2_profs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4186b6f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_pred_vs_true_counts(pred_logcounts, true_counts, save_path = None):\n",
    "    pred_logcounts = pred_logcounts.squeeze()\n",
    "    true_counts = true_counts.squeeze()\n",
    "    \n",
    "    # if the model preds/data are multi-stranded, sum across the two strands\n",
    "    if len(pred_logcounts.shape) > 1:\n",
    "        pred_logcounts = np.log(np.sum(np.exp(pred_logcounts), axis=-1))\n",
    "    if len(true_counts.shape) > 1:\n",
    "        true_counts = np.sum(true_counts, axis=-1)\n",
    "    \n",
    "    assert pred_logcounts.shape == true_counts.shape\n",
    "    \n",
    "    pred_counts = np.exp(pred_logcounts)\n",
    "    true_logcounts = np.log1p(true_counts)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(2, 2), dpi=300)\n",
    "\n",
    "    plt.scatter(pred_counts, true_counts,\n",
    "                alpha = 0.03, s = 1, color=\"k\")\n",
    "\n",
    "    plt.semilogx()\n",
    "    plt.semilogy()\n",
    "\n",
    "    plt.ylabel(\"Observed Reads\", fontsize=11)\n",
    "    plt.xlabel(\"Predicted Reads\", fontsize=11)\n",
    "    \n",
    "    # add the pearson correlation text to the top left\n",
    "    # (coordinates hard-coded: adjust as neeeded)\n",
    "    pearson_r = np.corrcoef(pred_logcounts, true_logcounts)[0,1]\n",
    "    plt.text(12, 10000, r'$r = %0.2f$' % pearson_r, fontsize=10)\n",
    "\n",
    "    # aesthetics\n",
    "    ax = plt.gca()\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_linewidth(1.2)\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_color(\"#333333\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    ax.tick_params(\"both\", labelsize=8)\n",
    "        \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "plot_pred_vs_true_counts(pred_logcounts, true_counts, save_path = figures_dir + \"1C_pred_v_true_scatter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17af8d55",
   "metadata": {},
   "source": [
    "### Profile Task Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ddb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_train_obs_profile_over_folds(true_profs, fold_labels):\n",
    "    # For each fold, calculate the average PRO-cap profile across all examples\n",
    "    # in the training or validation (not-test) sets (to use as a baseline).\n",
    "    # Then, build a list the same length as fold_labels, where the ith entry\n",
    "    # is the average train-val profile for the fold that example i belonged to.\n",
    "    \n",
    "    folds = sorted(list(set(fold_labels)))\n",
    "    \n",
    "    avg_profiles = []\n",
    "    for fold in folds:\n",
    "        # convert numeric fold labels to booleans\n",
    "        in_train_val_fold = np.array([fold_label != fold for fold_label in fold_labels])\n",
    "        \n",
    "        # subset to profiles that were in the train-val sets for this fold\n",
    "        true_profs_fold = true_profs[in_train_val_fold]\n",
    "        \n",
    "        # calculate mean per-base, keeping strands separate\n",
    "        avg_profiles.append(np.mean(true_profs_fold, axis=0))\n",
    "        \n",
    "    avg_profiles_tiled = []\n",
    "    for fold_label in fold_labels:\n",
    "        avg_profiles_tiled.append(avg_profiles[fold_label])\n",
    "    return np.array(avg_profiles_tiled)\n",
    "\n",
    "    \n",
    "avg_profiles_over_folds = get_avg_train_obs_profile_over_folds(true_profs, fold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18b768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_profile_jsds_and_corrs(profs1, profs2):\n",
    "    assert profs1.shape == profs2.shape, (profs1.shape, profs2.shape)\n",
    "    \n",
    "    # assuming none of these profiles are in log-space\n",
    "\n",
    "    jsds = []\n",
    "    pearson_rs = []\n",
    "    for prof1, prof2 in zip(profs1, profs2):\n",
    "        # if multiple strands, flatten data across them into 1D array\n",
    "        prof1 = prof1.flatten()\n",
    "        prof2 = prof2.flatten()\n",
    "        \n",
    "        jsd = jensenshannon(prof1, prof2)\n",
    "        jsds.append(jsd)\n",
    "        \n",
    "        pearson_r = np.corrcoef(prof1, prof2)[0,1]\n",
    "        pearson_rs.append(pearson_r)\n",
    "        \n",
    "    return np.array(jsds), np.array(pearson_rs)\n",
    "    \n",
    "# compare model predictions vs. observed data on the test sets\n",
    "jsds_pred_vs_obs, pearson_rs_pred_vs_obs = calc_profile_jsds_and_corrs(true_profs, pred_profs)\n",
    "\n",
    "# baseline 1: observed data pseudoreplicate 1 vs. observed data pseudoreplicate 2 on test sets\n",
    "jsds_pseudoreps, pearson_rs_pseudoreps = calc_profile_jsds_and_corrs(pseudorep1_profs, pseudorep2_profs)\n",
    "\n",
    "# baseline 2: average data profile in the training + validation set vs. observed data on test sets\n",
    "jsds_avg_baseline, pearson_rs_avg_baseline = calc_profile_jsds_and_corrs(true_profs, avg_profiles_over_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212fee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prof_jsds_cdf(pred_vs_obs, rep_baseline, avg_baseline,\n",
    "                              save_path = None):\n",
    "\n",
    "    fig = plt.figure(figsize=(2,1), dpi=300)\n",
    "    \n",
    "    pred_vs_obs = np.sort(pred_vs_obs)\n",
    "    rep_baseline = np.sort(rep_baseline)\n",
    "    avg_baseline = np.sort(avg_baseline)\n",
    "    cdf = np.array(range(len(pred_vs_obs)))/float(len(pred_vs_obs))\n",
    "\n",
    "    plt.plot(avg_baseline, cdf, color=\"#A0CB95\", alpha=1, label=\"Avg. Profile vs. Observed\")\n",
    "    plt.plot(pred_vs_obs, cdf, color=\"#3C863C\", alpha=1, label=\"Predicted vs. Observed\")\n",
    "    plt.plot(rep_baseline, cdf, color=\"#003123\", alpha=1, label=\"Pseudoreplicates\")\n",
    "    \n",
    "    plt.xlabel(\"Jensen-Shannon\\nDistance\", fontsize = 10)\n",
    "    plt.ylabel(\"Cum. Frac.\\nTest Peaks\", fontsize = 10)\n",
    "    \n",
    "    plt.legend(fontsize=7.5, frameon=False, bbox_to_anchor=(0.45,1.78), loc=\"upper center\")\n",
    "\n",
    "    plt.xlim(-0, plt.gca().get_xlim()[1])\n",
    "    plt.xticks([0, 0.4, 0.8], fontsize=6)\n",
    "\n",
    "    plt.yticks([0, 1], fontsize=6)\n",
    "\n",
    "    # aesthetics\n",
    "    ax = plt.gca()\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_linewidth(1.2)\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_color(\"#333333\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.tick_params(\"y\", length=0, labelsize=7.5)\n",
    "    ax.tick_params(\"x\", length=2, labelsize=7.5)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_prof_jsds_cdf(jsds_pred_vs_obs, jsds_pseudoreps, jsds_avg_baseline,\n",
    "                   save_path = figures_dir + \"1D_jsd_fix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prof_pearson_rs_cdf(pred_vs_obs, rep_baseline, avg_baseline,\n",
    "                              save_path = None):\n",
    "\n",
    "    fig = plt.figure(figsize=(2,1), dpi=300)\n",
    "    \n",
    "    pred_vs_obs = np.sort(pred_vs_obs)\n",
    "    rep_baseline = np.sort(rep_baseline)\n",
    "    avg_baseline = np.sort(avg_baseline)\n",
    "    cdf = np.array(range(len(pred_vs_obs)))/float(len(pred_vs_obs))\n",
    "\n",
    "    plt.plot(avg_baseline, cdf, color=\"#A0CB95\", alpha=1, label=\"Avg. Profile vs. Observed\")\n",
    "    plt.plot(pred_vs_obs, cdf, color=\"#3C863C\", alpha=1, label=\"Predicted vs. Observed\")\n",
    "    plt.plot(rep_baseline, cdf, color=\"#003123\", alpha=1, label=\"Pseudoreplicates\")\n",
    "    \n",
    "    plt.xlabel(\"Profile Pearson Corr.\", fontsize = 10)\n",
    "    plt.ylabel(\"Cum. Frac.\\nTest Peaks\", fontsize = 10)\n",
    "    \n",
    "    plt.legend(fontsize=7.5, frameon=False, bbox_to_anchor=(0.45,1.78), loc=\"upper center\")\n",
    "\n",
    "    #plt.xlim(-0, plt.gca().get_xlim()[1])\n",
    "    plt.xlim(-0.15, 1.02)\n",
    "    #plt.xticks([0, 0.4, 0.8], fontsize=6)\n",
    "\n",
    "    plt.yticks([0, 1], fontsize=6)\n",
    "\n",
    "    # aesthetics\n",
    "    ax = plt.gca()\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_linewidth(1.2)\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_color(\"#333333\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    \n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.tick_params(\"y\", length=0, labelsize=7.5)\n",
    "    ax.tick_params(\"x\", length=2, labelsize=7.5)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_prof_pearson_rs_cdf(pearson_rs_pred_vs_obs, pearson_rs_pseudoreps, pearson_rs_avg_baseline,\n",
    "                         save_path = figures_dir + \"1D_pearson_r_fix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f938672e",
   "metadata": {},
   "source": [
    "### Normalize Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_profile_metric(metrics_pred_vs_obs, metrics_upper_bound, metrics_lower_bound,\n",
    "                             bigger_is_worse = False):\n",
    "    assert metrics_pred_vs_obs.shape == metrics_upper_bound.shape\n",
    "    assert metrics_upper_bound.shape == metrics_lower_bound.shape\n",
    "    \n",
    "    # For each locus/peak/example, min-max normalize the performance metric\n",
    "    # using the replicate performance as the upper bound and the \"average profile\"\n",
    "    # baseline as the lower bound.\n",
    "    \n",
    "    norm_metrics = (metrics_pred_vs_obs - metrics_lower_bound) / (metrics_upper_bound - metrics_lower_bound)\n",
    "    \n",
    "    # If bigger values for the original metric mean worse performance,\n",
    "    # we want the normalized metric to follow the same pattern,\n",
    "    # so we need to flip the direction of the norm metric \n",
    "    if bigger_is_worse:\n",
    "        norm_metrics = 1 - norm_metrics\n",
    "    \n",
    "    norm_metrics = np.clip(norm_metrics, 0, 1)\n",
    "    return norm_metrics\n",
    "\n",
    "\n",
    "norm_jsds = normalize_profile_metric(jsds_pred_vs_obs, jsds_pseudoreps, jsds_avg_baseline,\n",
    "                                     bigger_is_worse = True)\n",
    "\n",
    "norm_pearson_rs = normalize_profile_metric(pearson_rs_pred_vs_obs, pearson_rs_pseudoreps, pearson_rs_avg_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989085c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# why swap from JSDs to Pearson corrs: after normalization, corr is less confounded by counts?\n",
    "\n",
    "print(np.corrcoef(np.log(true_counts.sum(axis=-1)), jsds_pred_vs_obs)[0,1])\n",
    "plt.scatter(np.log(true_counts.sum(axis=-1)), jsds_pred_vs_obs, alpha=0.1, s=8)\n",
    "plt.show()\n",
    "print(np.corrcoef(np.log(true_counts.sum(axis=-1)), norm_jsds)[0,1])\n",
    "plt.scatter(np.log(true_counts.sum(axis=-1)), norm_jsds, alpha=0.1, s=8)\n",
    "plt.show()\n",
    "\n",
    "print(np.corrcoef(np.log(true_counts.sum(axis=-1)), pearson_rs_pred_vs_obs)[0,1])\n",
    "plt.scatter(np.log(true_counts.sum(axis=-1)), pearson_rs_pred_vs_obs, alpha=0.1, s=8)\n",
    "plt.show()\n",
    "print(np.corrcoef(np.log(true_counts.sum(axis=-1)), norm_pearson_rs)[0,1])\n",
    "plt.scatter(np.log(true_counts.sum(axis=-1)), norm_pearson_rs, alpha=0.1, s=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5695ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratify_profile_metrics_over_folds(prof_metrics, fold_labels):\n",
    "    folds = sorted(list(set(fold_labels)))\n",
    "    \n",
    "    aggregated_metric_per_fold = []\n",
    "    for fold in folds:\n",
    "        # convert numeric fold labels to booleans\n",
    "        in_fold = np.array([fold_num == fold for fold_num in fold_labels])\n",
    "        \n",
    "        prof_metrics_fold = prof_metrics[in_fold]\n",
    "        \n",
    "        aggregated_metric_per_fold.append(np.mean(prof_metrics_fold))\n",
    "        \n",
    "    print(\"Metric Average Within Each Fold's Test Set:\")\n",
    "    print(aggregated_metric_per_fold)\n",
    "    \n",
    "    print(\"\\nMetric Average, Averaged Across Folds:\")\n",
    "    print(np.mean(aggregated_metric_per_fold))\n",
    "    \n",
    "    print(\"\\nStandard Deviation of Metric Average Across Folds:\")\n",
    "    print(np.std(aggregated_metric_per_fold), \"\\n\")\n",
    "    \n",
    "\n",
    "print(\"--- Pearson Corr ---\")\n",
    "stratify_profile_metrics_over_folds(pearson_rs_pred_vs_obs, fold_labels)\n",
    "\n",
    "print(\"--- Normalized Pearson Corr ---\")\n",
    "stratify_profile_metrics_over_folds(norm_pearson_rs, fold_labels)\n",
    "\n",
    "print(\"--- JSD ---\")\n",
    "stratify_profile_metrics_over_folds(jsds_pred_vs_obs, fold_labels)\n",
    "\n",
    "print(\"--- Normalized JSD ---\")\n",
    "stratify_profile_metrics_over_folds(norm_jsds, fold_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e048c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for baselines\n",
    "\n",
    "\n",
    "print(\"--- Pearson Corr, Pseudoreplicate Baseline ---\")\n",
    "stratify_profile_metrics_over_folds(pearson_rs_pseudoreps, fold_labels)\n",
    "\n",
    "print(\"--- Pearson Corr, Average Profile Baseline ---\")\n",
    "stratify_profile_metrics_over_folds(pearson_rs_avg_baseline, fold_labels)\n",
    "\n",
    "print(\"--- JSD, Pseudoreplicate Baseline ---\")\n",
    "stratify_profile_metrics_over_folds(jsds_pseudoreps, fold_labels)\n",
    "\n",
    "print(\"--- JSD, Average Profile Baseline ---\")\n",
    "stratify_profile_metrics_over_folds(jsds_avg_baseline, fold_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1baa6b",
   "metadata": {},
   "source": [
    "## Plot Individual Example Loci + Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84901a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_scores = np.load(merged_config.profile_onehot_scores_path)\n",
    "counts_scores = np.load(merged_config.counts_onehot_scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions so that I can find the exact PRO-cap peak matching\n",
    "# where I found something in the genome browser\n",
    "\n",
    "def _overlap(coord1, coord2):\n",
    "    # chromosome should be the same\n",
    "    if coord1[0] != coord2[0]:\n",
    "        return False\n",
    "    if coord2[2] < coord1[1]:\n",
    "        return False\n",
    "    if coord2[1] > coord1[2]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_locus_index(coords, chrom, start, end):\n",
    "    # returns the peak index and the peak coordinates for whatever PRO-cap peak\n",
    "    # is the closest match to the chrom-start-end info you input\n",
    "    \n",
    "    assert type(chrom) == str, chrom\n",
    "    assert type(start) == int, start\n",
    "    assert type(end) == int, end\n",
    "    coord_to_find = (chrom, start, end)\n",
    "    \n",
    "    match_indexes = []\n",
    "    matches = []\n",
    "    for index, coord in enumerate(coords):\n",
    "        if _overlap(coord, coord_to_find):\n",
    "            matches.append(coord)\n",
    "            match_indexes.append(index)\n",
    "            \n",
    "    if len(matches) == 0:\n",
    "        print(\"Coordinate not found :(\")\n",
    "        return None\n",
    "    elif len(matches) > 1:\n",
    "        print(str(len(matches)) + \" matches to coordinate found: \", coord_to_find)\n",
    "    else:\n",
    "        print(coord_to_find, \"--->\", matches[0])\n",
    "        return match_indexes[0], matches[0]\n",
    "        \n",
    "    mid_for_coord_to_find = (start + end) // 2\n",
    "    dists_for_matches = [abs(((c[1] + c[2]) // 2) - mid_for_coord_to_find) for c in matches]\n",
    "    closest_match_index = match_indexes[np.argmin(dists_for_matches)]\n",
    "    closest_match = matches[np.argmin(dists_for_matches)]\n",
    "    \n",
    "    print(coord_to_find, \"--->\", closest_match)\n",
    "    \n",
    "    return closest_match_index, closest_match\n",
    "        \n",
    "\n",
    "tal1_altpromoter_index, _ = get_locus_index(all_coords, \"chr1\", 47231230, 47231655)\n",
    "gata1_enhancer_index, _ = get_locus_index(all_coords, \"chrX\", 48789633, 48789866)\n",
    "hbe1_promoter_index, hbe1_promoter_coords = get_locus_index(all_coords, \"chr11\", 5269828, 5270185)\n",
    "hbe1_enhancer_index, hbe1_enhancer_coords = get_locus_index(all_coords, \"chr11\", 5288180, 5288433)\n",
    "\n",
    "# ended up going with these:\n",
    "pola1_promoter_index, pola1_promoter_coords = get_locus_index(all_coords, \"chrX\", 24693718, 24693987)\n",
    "pola1_enhancer_index, pola1_enhancer_coords = get_locus_index(all_coords, \"chrX\", 24297329, 24297563)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19698fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motif_on_ax_modified(pwm, ax):\n",
    "    # \"modified\" = different from the version of this function in other_motif_utils.py,\n",
    "    # because the axes have to be treated differently for this megaplot\n",
    "    \n",
    "    # given a PWM/CWM/contribution scores array and a matplotlib axis, this function\n",
    "    # draws the letters at the heights specificed by the array\n",
    "    \n",
    "    # expecting either (n x 4) motif or (n x 4) one-hot encoded scores\n",
    "    assert len(pwm.shape) == 2 and pwm.shape[-1] == 4, pwm.shape\n",
    "    # reformat pwm to what logomaker expects\n",
    "    df = pd.DataFrame(pwm, columns=['A', 'C', 'G', 'T'])\n",
    "    df.index.name = 'pos'\n",
    "\n",
    "    # plot motif (\"baseline_width=0\" removes the y=0 line)\n",
    "    logomaker.Logo(df, ax=ax, font_name='Arial Rounded', baseline_width=0)\n",
    "    \n",
    "    ax.set_ylim(min(df.sum(axis=1).min(), 0), df.sum(axis=1).max())\n",
    "\n",
    "\n",
    "def plot_example(true_profile, pred_profile, prof_scores, counts_scores,\n",
    "                 locus_coords, zoom_mid = None, zoom_width = None, in_window = in_window,\n",
    "                 prof_len = out_window, title = None, linewidth=None, label_strands = True,\n",
    "                 imp_score_pad = 0.185, fig_width = 3, save_path = None):\n",
    "    \n",
    "    num_subplots = 4\n",
    "    \n",
    "    fig, axes = plt.subplots(num_subplots, figsize=(fig_width, 2.7),\n",
    "                             sharex=True, dpi=300,\n",
    "                             gridspec_kw = {\"height_ratios\" : [1,1,0.6,0.75]})\n",
    "    plt.tight_layout(pad=0)\n",
    "    \n",
    "    if title is not None:\n",
    "        fig.suptitle(title, x=0.53, y = 1.08, fontsize=14, horizontalalignment='center')\n",
    "    \n",
    "    axis_fontsize = 10\n",
    "    prof_linewidth = 1.2\n",
    "    if linewidth is not None:\n",
    "        prof_linewidth *= linewidth\n",
    "    \n",
    "    \n",
    "    # plot the observed profile, both strands\n",
    "    \n",
    "    x_range = np.arange(0,prof_len)\n",
    "    offset = np.max(np.abs(true_profile)) * 0.02  # offset needed to see both strands' lines\n",
    "    \n",
    "    axes[0].plot(x_range, true_profile[0] + offset,\n",
    "                 alpha=1, c = \"#001DAC\", linewidth=prof_linewidth)\n",
    "    axes[0].plot(x_range, -1 * true_profile[1] - offset,\n",
    "                 alpha=0.7, c = \"#001DAC\", linewidth=prof_linewidth)\n",
    "    axes[0].set_ylabel(\"Observed\\nReads\", fontsize = axis_fontsize)\n",
    "    \n",
    "    \n",
    "    # plot the predicted profile, both strands\n",
    "    \n",
    "    offset = np.max(np.abs(pred_profile)) * 0.02\n",
    "    \n",
    "    axes[1].plot(x_range, pred_profile[0] + offset,\n",
    "                 alpha=1, c = \"#1B5AE3\", linewidth=prof_linewidth)\n",
    "    axes[1].plot(x_range, -1 * pred_profile[1] - offset,\n",
    "                 alpha=0.7, c = \"#1B5AE3\", linewidth=prof_linewidth)\n",
    "    axes[1].set_ylabel(\"Predicted\\nReads\", fontsize = axis_fontsize)\n",
    "    \n",
    "    print(\"Correlation between predicted and observed profile in this window:\")\n",
    "    print(np.corrcoef(true_profile[:, zoom_mid - zoom_width : zoom_mid + zoom_width].flatten(),\n",
    "            pred_profile[:, zoom_mid - zoom_width : zoom_mid + zoom_width].flatten())[0,1])\n",
    "\n",
    "    \n",
    "    # plot the profile and counts task contribution scores\n",
    "    \n",
    "    # need to slice accounting for difference between score width (input size of model)\n",
    "    # vs. pred or obs profile width (output size of model)\n",
    "    in_out_size_diff = (in_window - out_window) // 2\n",
    "    prof_scores = prof_scores[:, in_out_size_diff : in_window - in_out_size_diff]\n",
    "    counts_scores = counts_scores[:, in_out_size_diff : in_window - in_out_size_diff]\n",
    "    \n",
    "    plot_motif_on_ax_modified(prof_scores.T, axes[2])\n",
    "    plot_motif_on_ax_modified(counts_scores.T, axes[3])\n",
    "    \n",
    "    axes[2].set_ylabel(\" Profile\", fontsize = axis_fontsize - 2)\n",
    "    axes[3].set_ylabel(\"Counts \", fontsize = axis_fontsize - 2)\n",
    "    \n",
    "    axes[2].annotate(\"Importance\\nScores\",\n",
    "            xy=(0, 0), xycoords='axes fraction',\n",
    "            xytext=(-imp_score_pad, -0.35), textcoords='axes fraction',\n",
    "            horizontalalignment='center', verticalalignment='center',\n",
    "            fontsize=axis_fontsize, rotation=90)\n",
    "    \n",
    "    \n",
    "    # zoom into correct position, set x-axis tick values to actual coordinates\n",
    "    \n",
    "    if zoom_mid is not None and zoom_width is not None:\n",
    "        zoom_lims = (zoom_mid - zoom_width, zoom_mid + zoom_width)\n",
    "        plt.xlim(zoom_lims)\n",
    "        \n",
    "        # this should be 2114\n",
    "        locus_coords_width = locus_coords[2] - locus_coords[1]\n",
    "        # a 0 on this plot's axis corresponds to position [xticks_offset] on this chromosome\n",
    "        xticks_offset = locus_coords[1] + (locus_coords_width - prof_len) // 2\n",
    "        \n",
    "        # modify the xticks to reflect actual genomic coordinates\n",
    "        og_xticks = axes[-1].get_xticks()[1:-1:2]\n",
    "        xticks = [int(xt + xticks_offset) for xt in og_xticks]\n",
    "        plt.xticks(og_xticks, xticks)\n",
    "        \n",
    "        axes[-1].set_xlabel(locus_coords[0], style=\"italic\")\n",
    "    else:\n",
    "        x_axis_buffer = 10\n",
    "        plt.xlim(- x_axis_buffer, prof_len + x_axis_buffer)\n",
    "        \n",
    "        axes[-1].set_xlabel(\"Genomic Axis\", fontsize = axis_fontsize)\n",
    "    \n",
    "    \n",
    "    # aesthetics\n",
    "    \n",
    "    # plot y-axis for profiles, not for scores\n",
    "    \n",
    "    for ax in axes[:2]:\n",
    "        ax.tick_params(\"y\", length=0, labelsize=9)\n",
    "        ax.set_yticks(ax.get_yticks(minor=False)[1:-1],\n",
    "                      np.abs(ax.get_yticks(minor=False)).astype(int)[1:-1])\n",
    "        \n",
    "    for ax in axes[2:]:\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # only draw x-axis line for bottom plot\n",
    "    \n",
    "    for ax in axes[:-1]:\n",
    "        ax.spines[\"bottom\"].set_visible(False)\n",
    "        ax.tick_params(\"x\", length=0)\n",
    "            \n",
    "    axes[-1].spines[\"bottom\"].set_linewidth(1.5)\n",
    "    axes[-1].spines[\"bottom\"].set_color(\"#333333\")\n",
    "    axes[-1].tick_params(\"x\", labelsize=9)\n",
    "    \n",
    "    for ax in axes:\n",
    "        ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "        ax.spines[\"left\"].set_linewidth(1.5)\n",
    "        ax.spines[\"left\"].set_color(\"#333333\")\n",
    "\n",
    "    # put more space between scoes and x-axis line\n",
    "    \n",
    "    axes[-1].set_ylim(axes[-1].get_ylim()[0] * 2.5, axes[-1].set_ylim()[1])\n",
    "    \n",
    "    \n",
    "    # add little text near edge of profile saying that the two lines are the two strands\n",
    "    \n",
    "    if label_strands == True:\n",
    "        ymin, ymax = axes[0].get_ylim()\n",
    "        zero_point = - ymin / (ymax - ymin)\n",
    "        \n",
    "        axes[0].annotate(r'$fwd. strand$',\n",
    "            xy=(0.1, 0.1), xycoords='axes fraction',\n",
    "            xytext=(0.03, zero_point + 0.2), textcoords='axes fraction',\n",
    "            horizontalalignment='left', verticalalignment='top',\n",
    "            fontsize=7, color=\"#001DAC\", alpha=0.9)\n",
    "        axes[0].annotate(r'$rev. strand$',\n",
    "            xy=(0.1, 0.1), xycoords='axes fraction',\n",
    "            xytext=(0.03, zero_point - 0.08), textcoords='axes fraction',\n",
    "            horizontalalignment='left', verticalalignment='top',\n",
    "            fontsize=7, color=\"#001DAC\", alpha=0.6)\n",
    "        \n",
    "    elif label_strands == \"right\":\n",
    "        ymin, ymax = axes[0].get_ylim()\n",
    "        zero_point = - ymin / (ymax - ymin)\n",
    "        \n",
    "        axes[0].annotate(r'$fwd. strand$',\n",
    "            xy=(0.1, 0.1), xycoords='axes fraction',\n",
    "            xytext=(1, zero_point + 0.2), textcoords='axes fraction',\n",
    "            horizontalalignment='right', verticalalignment='top',\n",
    "            fontsize=7, color=\"#001DAC\", alpha=0.9)\n",
    "        axes[0].annotate(r'$rev. strand$',\n",
    "            xy=(0.1, 0.1), xycoords='axes fraction',\n",
    "            xytext=(1, zero_point - 0.08), textcoords='axes fraction',\n",
    "            horizontalalignment='right', verticalalignment='top',\n",
    "            fontsize=7, color=\"#001DAC\", alpha=0.6)\n",
    "    \n",
    "    \n",
    "    fig.align_ylabels(axes[:2])\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example(true_profs[pola1_promoter_index],\n",
    "             pred_profs[pola1_promoter_index] * np.exp(pred_logcounts[pola1_promoter_index]),\n",
    "             prof_scores[pola1_promoter_index],\n",
    "             counts_scores[pola1_promoter_index],\n",
    "             pola1_promoter_coords, zoom_mid = 510, zoom_width = 85,\n",
    "             imp_score_pad = 0.0925, fig_width = 5.5,\n",
    "             title=r'$\\it{POLA1}$ Promoter', label_strands = True,\n",
    "             save_path = figures_dir + \"1B_pola1_promoter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c975d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_example(true_profs[pola1_enhancer_index],\n",
    "             pred_profs[pola1_enhancer_index] * np.exp(pred_logcounts[pola1_enhancer_index]),\n",
    "             prof_scores[pola1_enhancer_index],\n",
    "             counts_scores[pola1_enhancer_index],\n",
    "             pola1_enhancer_coords, zoom_mid = 525, zoom_width = 40,\n",
    "             title=r'Enhancer Near $\\it{POLA1}$', label_strands = False,\n",
    "             \n",
    "            save_path = figures_dir + \"1B_pola1_enhancer.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93426034",
   "metadata": {},
   "source": [
    "## Stratify Model Performance Over Possible Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb58d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ois = get_orientation_indexes(true_profs)\n",
    "nsis = get_norm_shannon_entropies(true_profs, true_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7cf42f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(np.corrcoef(ois, jsds_pred_vs_obs)[0,1])\n",
    "plt.scatter(ois, jsds_pred_vs_obs, alpha=0.1, s=8)\n",
    "plt.show()\n",
    "\n",
    "print(np.corrcoef(ois, norm_jsds)[0,1])\n",
    "plt.scatter(ois, norm_jsds, alpha=0.1, s=8)\n",
    "plt.show()\n",
    "\n",
    "print(np.corrcoef(ois, pearson_rs_pred_vs_obs)[0,1])\n",
    "plt.scatter(ois, pearson_rs_pred_vs_obs, alpha=0.1, s=8)\n",
    "plt.show()\n",
    "print(np.corrcoef(ois, norm_pearson_rs)[0,1])\n",
    "plt.scatter(ois, norm_pearson_rs, alpha=0.1, s=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.corrcoef(np.log(true_counts.sum(axis=-1))[ois < 0.99], pearson_rs_pred_vs_obs[ois < 0.99])[0,1])\n",
    "plt.scatter(np.log(true_counts.sum(axis=-1))[ois < 0.99], pearson_rs_pred_vs_obs[ois < 0.99], alpha=0.1, s=8)\n",
    "plt.show()\n",
    "print(np.corrcoef(np.log(true_counts.sum(axis=-1))[ois < 0.99], norm_pearson_rs[ois < 0.99])[0,1])\n",
    "plt.scatter(np.log(true_counts.sum(axis=-1))[ois < 0.99], norm_pearson_rs[ois < 0.99], alpha=0.1, s=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e750aa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_metrics_by_covariate(metrics, covariate, xlabel, ylabel, save_path = None):\n",
    "    print(\"Pearson r, metric vs. covariate:\", np.corrcoef(metrics, covariate)[0,1])\n",
    "    \n",
    "    plt.figure(figsize=(1.5, 1.5), dpi=300)\n",
    "    \n",
    "    plt.scatter(covariate,\n",
    "                metrics,\n",
    "                s = 3, alpha=0.05, linewidths=0, color=\"midnightblue\")\n",
    "\n",
    "    plt.xlabel(xlabel, fontsize=10)\n",
    "    plt.ylabel(ylabel, fontsize=10)\n",
    "    \n",
    "    # aesthetics\n",
    "    ax = plt.gca()\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_linewidth(1.2)\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_color(\"#333333\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    ax.tick_params(length=2, labelsize=7)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "plot_metrics_by_covariate(norm_jsds, ois, \"Orientation Index\", \"Normalized JSD\",\n",
    "                          save_path = figures_dir + \"S1_OI_by_norm_jsd.png\")\n",
    "plot_metrics_by_covariate(norm_jsds, nsis, \"Norm. Shape Index\", \"Normalized JSD\",\n",
    "                          save_path = figures_dir + \"S1_NSI_by_norm_jsd.png\")\n",
    "\n",
    "plot_metrics_by_covariate(jsds_pred_vs_obs, ois, \"Orientation Index\", \"JSD\",\n",
    "                          save_path = figures_dir + \"S1_OI_by_jsd.png\")\n",
    "plot_metrics_by_covariate(jsds_pred_vs_obs, nsis, \"Norm. Shape Index\", \"JSD\",\n",
    "                          save_path = figures_dir + \"S1_NSI_by_jsd.png\")\n",
    "\n",
    "plot_metrics_by_covariate(norm_pearson_rs, ois, \"Orientation Index\", \"Norm. Profile\\nPearson Corr.\",\n",
    "                          save_path = figures_dir + \"S1_OI_by_norm_pearson.png\")\n",
    "plot_metrics_by_covariate(norm_pearson_rs, nsis, \"Norm. Shape Index\", \"Norm. Profile\\nPearson Corr.\",\n",
    "                          save_path = figures_dir + \"S1_NSI_by_norm_pearson.png\")\n",
    "    \n",
    "plot_metrics_by_covariate(pearson_rs_pred_vs_obs, ois, \"Orientation Index\", \"Profile Pearson Corr.\",\n",
    "                          save_path = figures_dir + \"S1_OI_by_pearson.png\")\n",
    "plot_metrics_by_covariate(pearson_rs_pred_vs_obs, nsis, \"Norm. Shape Index\", \"Profile Pearson Corr.\",\n",
    "                          save_path = figures_dir + \"S1_NSI_by_pearson.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f6c1d",
   "metadata": {},
   "source": [
    "## Stratify Model Performance Across cCREs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa0587",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# essentially, run bedtools intersect between PRO-cap peaks and cCRE annotations\n",
    "# (takes a second to run)\n",
    "\n",
    "# cCRE annotations are cell-type-specific, from ENCODE 2020 paper:\n",
    "#  \"Expanded encyclopaedias of DNA elements in the human and mouse genomes.\" (Nature)\n",
    "\n",
    "ccre_annots = find_peak_overlap_labels(all_coords,\n",
    "                                       get_ccre_bed(cell_type, proj_dir),\n",
    "                                       in_window, out_window)\n",
    "\n",
    "# break down category of \"promoter\" (PLS) into promoters\n",
    "# with vs. without proximal enhancers (pELS)\n",
    "\n",
    "ccre_annots[\"PLS_no_pELS\"] = ccre_annots[\"PLS\"] * (~ ccre_annots[\"pELS\"])\n",
    "ccre_annots[\"PLS_with_pELS\"] = ccre_annots[\"PLS\"] * ccre_annots[\"pELS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a13988",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_stratify_but_subset(metrics, ccre_annots, metric_name, save_path = None):\n",
    "    \n",
    "    annots_to_colors = {\"PLS\" : \"#f94144\",\n",
    "                        \"pELS\" : \"#ffbc42\",\n",
    "                        \"dELS\" : \"#05668d\",\n",
    "                        \"PLS_with_pELS\" : \"#f94144\",\n",
    "                        \"PLS_no_pELS\" : \"#ffbc42\"}\n",
    "\n",
    "    annots_to_labels = {\"PLS\" : \"Promoters\",\n",
    "                        \"pELS\" : \"Proximal\\nEnhancers\",\n",
    "                        \"dELS\" : \"Distal\\nEnhancers\",\n",
    "                        \"PLS_with_pELS\" : \"Promoters w/\\nProx. Enhancers\",\n",
    "                        \"PLS_no_pELS\" : \"Promoters w/o\\nProx. Enhancers\"}\n",
    "\n",
    "    annots_to_plot = [\"PLS_with_pELS\", \"PLS_no_pELS\", \"dELS\"]\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(2, 1.4), dpi=300)\n",
    "\n",
    "    # draw vertical line to show the median metric value across the whole dataset\n",
    "    plt.axvline(np.median(metrics), linestyle=\"dashed\", alpha=0.5, color=\"k\", linewidth=1)\n",
    "    \n",
    "    y_index = 0\n",
    "    \n",
    "    # plot first row: whole dataset\n",
    "    plot_scatter_and_boxplot(metrics, y_index, color=\"#999999\", dot_alpha=0.03)\n",
    "    y_index += 1\n",
    "    y_labels = [\"All Peaks\"]\n",
    "    yticks = [0]\n",
    "    \n",
    "    # for subsequent rows, add a small, consistent offset so the first row gets some space \n",
    "    y_offset = 0.1\n",
    "    \n",
    "    # for each annotation to stratify over, plot a row for that subset of the data\n",
    "    for annot_name in annots_to_plot:\n",
    "        y_labels.append(annots_to_labels[annot_name])\n",
    "        yticks.append(y_index + y_offset)\n",
    "        metrics_subset = metrics[ccre_annots[annot_name]]\n",
    "        plot_scatter_and_boxplot(metrics_subset, y_index + y_offset,\n",
    "                                 color = annots_to_colors[annot_name],\n",
    "                                 dot_alpha = 0.05)\n",
    "        y_index += 1\n",
    "\n",
    "    plt.xlabel(metric_name, fontsize=11)\n",
    "    \n",
    "    plt.yticks(yticks, y_labels, fontsize = 8)\n",
    "    plt.ylim(plt.gca().get_ylim()[1], plt.gca().get_ylim()[0] - 0.1)\n",
    "    \n",
    "    # aesthetics\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_linewidth(1.2)\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_color(\"#333333\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.tick_params(length=2)\n",
    "    plt.xticks(fontsize=8)\n",
    "\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "plot_stratify_but_subset(norm_pearson_rs, ccre_annots, \"Normalized Profile\\n\" + r'Pearson Corr.',\n",
    "                         save_path = figures_dir + \"1E_stratify_cCREs_norm_pearson.png\")\n",
    "    \n",
    "plot_stratify_but_subset(pearson_rs_pred_vs_obs, ccre_annots, \"Profile Pearson Corr.\",\n",
    "                         save_path = figures_dir + \"1E_stratify_cCREs_pearson.png\")\n",
    "\n",
    "plot_stratify_but_subset(norm_jsds, ccre_annots, \"Normalized JSD\",\n",
    "                         save_path = figures_dir + \"1E_stratify_cCREs_norm_jsd.png\")\n",
    "    \n",
    "plot_stratify_but_subset(jsds_pred_vs_obs, ccre_annots, \"JSD\",\n",
    "                         save_path = figures_dir + \"1E_stratify_cCREs_jsd.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb2e86",
   "metadata": {},
   "source": [
    "## More Stratification (Supplement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572fd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_pred_counts_by_annot(true_counts, pred_logcounts, overlap_annots_bools,\n",
    "                                   save_path = None):\n",
    "    \n",
    "    annots_to_labels = {\"PLS\" : \"Promoters\",\n",
    "                        \"pELS\" : \"Proximal Enhancers\",\n",
    "                        \"dELS\" : \"Distal Enhancers\",\n",
    "                        \"PLS_with_pELS\" : \"Promoters With\\nProximal Enhancers\",\n",
    "                        \"PLS_no_pELS\" : \"Promoters Without\\nProximal Enhancers\" }\n",
    "    \n",
    "    annots_to_colors = {\"PLS\" : \"#f94144\",\n",
    "                        \"pELS\" : \"#ffbc42\",\n",
    "                        \"dELS\" : \"#05668d\",\n",
    "                        \"PLS_with_pELS\" : \"#f94144\",\n",
    "                        \"PLS_no_pELS\" : \"#ffbc42\"}\n",
    "    \n",
    "    fig, axes = plt.subplots(1,3,figsize=(8,1.8))\n",
    "    \n",
    "    annots_to_plot = [\"PLS_with_pELS\", \"PLS_no_pELS\", \"dELS\"] #[\"PLS\", \"pELS\", \"dELS\"]\n",
    "    \n",
    "    \n",
    "    # get union of all the points you're going to plot as separate groups\n",
    "    \n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for annot_name in annots_to_plot:\n",
    "        all_x.extend(np.exp(pred_logcounts[overlap_annots_bools[annot_name]]).squeeze())\n",
    "        all_y.extend(true_counts[overlap_annots_bools[annot_name]].squeeze())\n",
    "    \n",
    "    \n",
    "    for ax, sup_annot_name in zip(axes, annots_to_plot):\n",
    "        \n",
    "        # first, plot all the points in light gray as a background\n",
    "        \n",
    "        ax.scatter(all_x, all_y, alpha = 1, s = 3, color = \"lightgray\")\n",
    "        \n",
    "        # then get subset of dataset overlapping the annotation/cCRE label\n",
    "        true_counts_subset = true_counts[overlap_annots_bools[sup_annot_name]].squeeze()\n",
    "        pred_logcounts_subset = pred_logcounts[overlap_annots_bools[sup_annot_name]].squeeze()\n",
    "        \n",
    "        # print some stats to report in text\n",
    "        \n",
    "        mse = np.mean((pred_logcounts_subset - np.log1p(true_counts_subset)) ** 2)\n",
    "        print(sup_annot_name)\n",
    "        print(\"Pred. vs. Obs. MSE:\", mse)\n",
    "        print(\"Pred vs. Obs Pearson r:\", np.corrcoef(pred_logcounts_subset, np.log1p(true_counts_subset))[0,1])\n",
    "        print(\"Pred vs. Obs Spearman r:\", spearmanr(pred_logcounts_subset,\n",
    "                                                    np.log1p(true_counts_subset)).correlation)\n",
    "        print(\"\")\n",
    "        \n",
    "        # plot the subset of the dataset overlapping this annotation/cCRE\n",
    "        \n",
    "        ax.scatter(np.exp(pred_logcounts_subset), true_counts_subset, alpha = 0.1, s = 3,\n",
    "                    label = annots_to_labels[sup_annot_name],\n",
    "                    color = annots_to_colors[sup_annot_name])\n",
    "\n",
    "        # aesthetics\n",
    "        \n",
    "        ax.semilogy()\n",
    "        ax.semilogx()\n",
    "\n",
    "        ax.set_xlabel(\"Predicted Reads\", fontsize = 12)\n",
    "        ax.set_ylabel(\"Observed Reads\", fontsize = 12)\n",
    "\n",
    "        ax.spines[[\"left\", \"bottom\"]].set_linewidth(1.5)\n",
    "        ax.spines[[\"left\", \"bottom\"]].set_color(\"#333333\")\n",
    "        ax.spines[[\"top\", \"right\"]].set_visible(False) \n",
    "        ax.tick_params(axis='both', labelsize=10, length=2)\n",
    "        \n",
    "        ax.set_xticks([10, 10**2, 10**3, 10**4])\n",
    "        ax.set_yticks([10, 10**2, 10**3, 10**4])\n",
    "        ax.minorticks_off()\n",
    "        \n",
    "        ax.set_title(annots_to_labels[sup_annot_name], fontsize=12, pad=10)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.6)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "plot_true_pred_counts_by_annot(true_counts.sum(axis=-1), pred_logcounts, ccre_annots,\n",
    "                               save_path = figures_dir + \"S1_counts_by_ccre.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate overall MSE\n",
    "\n",
    "mse = np.mean((pred_logcounts - np.log1p(true_counts.sum(axis=-1))) ** 2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946731b9",
   "metadata": {},
   "source": [
    "### Stratify by TATA box presence (based on motif hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f07c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_hit_counts = load_motif_hits(cell_type, model_type, data_type, in_window=in_window)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131d98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boolean list, where element i is True if PRO-cap peak i contains a TATA box\n",
    "\n",
    "# the function below is general enough to work for any motif name found in the motif hits\n",
    "\n",
    "def get_filter_for_peaks_with_motif(peak_hit_counts, motif_key_labels, motifs_to_find):\n",
    "    # motif_key_labels should be a list of motif names, the same list used\n",
    "    # when motif hits were called. The order must be kept the same too\n",
    "    \n",
    "    motif_bools = dict()\n",
    "    for motif in motifs_to_find:\n",
    "        assert motif in motif_key_labels, (motif, motif_key_labels)\n",
    "        motif_index = motif_key_labels.index(motif)\n",
    "        motif_bools[motif] = peak_hit_counts[\"profile\"][:, motif_index] > 0\n",
    "\n",
    "    return motif_bools\n",
    "\n",
    "motif_filters = get_filter_for_peaks_with_motif(peak_hit_counts, motif_names,\n",
    "                                                [\"TATA\", \"TATATA\"])\n",
    "\n",
    "# since we found two forms of the TATA box, we'll just merge the list for each into one\n",
    "\n",
    "motif_filters = {\"TATA\" : np.logical_or(motif_filters[\"TATA\"], motif_filters[\"TATATA\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c810ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to how we found overlap between peaks and cCRE annotations,\n",
    "# we can do bedtools-intersect-like logic to find peaks overlapping \n",
    "# annotations of housekeeping or TCT promoters\n",
    "\n",
    "# (see scripts in the 1_process_data/ folder for how these bed files were made)\n",
    "\n",
    "housekeeping_genes_bed = proj_dir + \"/annotations/hk_promoters_by_transcripts.bed\"\n",
    "hk_annots = find_peak_overlap(all_coords, housekeeping_genes_bed)\n",
    "\n",
    "tct_promoters_bed = proj_dir + \"/annotations/tct_promoters.bed\"\n",
    "tct_annots = find_peak_overlap(all_coords, tct_promoters_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d358579",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_regions_files = {\"genes\" : proj_dir + \"/annotations/gene_regions.bed\",\n",
    "                      \"TSSs\" : proj_dir + \"/annotations/TSSs.bed\",\n",
    "                      \"promoters\" : proj_dir + \"/annotations/promoters.bed\",\n",
    "                      \"intergenic\" : proj_dir + \"/annotations/intergenic_regions.bed\",\n",
    "                      \"exons\" : proj_dir + \"/annotations/exons.bed\",\n",
    "                      \"introns\" : proj_dir + \"/annotations/introns.bed\",\n",
    "                      \"utrs\" : proj_dir + \"/annotations/utrs.bed\"}\n",
    "\n",
    "gene_region_annots = get_gene_region_overlap(all_coords, gene_regions_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f71e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance between each PRO-cap peak center and the nearest GENCODE-annotated TSS\n",
    "\n",
    "TSS_dists = get_dist_to_TSS(all_coords, gene_regions_files[\"TSSs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc154cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to contrast peaks in promoters against peaks not in promoters,\n",
    "# but promoters technically overlap gene bodies by a little and intergenic regions too.\n",
    "# so, we'll adjust our labels for what type of genomic region a PRO-cap peak falls in\n",
    "# by making sure promoter-overlaps are labeled as such, and only non-promoter-overlaps\n",
    "# have other labels, like genic or intergenic.\n",
    "\n",
    "gene_region_names = list(gene_region_annots.keys())\n",
    "for region in gene_region_names:\n",
    "    if \"promoters\" in region or \"TSSs\" in region:\n",
    "        continue\n",
    "    if \"_not_TSS\" in region:  # this is here to avoid bugs if you re-run this cell again\n",
    "        continue\n",
    "        \n",
    "    gene_region_annots[region + \"_not_TSS\"] = gene_region_annots[region] * (~ gene_region_annots[\"promoters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some stats about how these annotations overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d6834",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccre_annots[\"PLS\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b533721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not perfect agreement between \"PLS\" category and GENCODE-transcript promoters :/\n",
    "(ccre_annots[\"PLS\"] * gene_region_annots[\"promoters\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d976a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many PRO-cap peaks overlap both a gene body and a region outside a gene body?\n",
    "# (how many peaks are on the boundary of a gene, like a promoter should be)\n",
    "(gene_region_annots[\"genes\"] * gene_region_annots[\"intergenic\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366199e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 91% of peaks on gene boundaries are actually annotated as promoters, good\n",
    "(gene_region_annots[\"genes\"] * gene_region_annots[\"intergenic\"] * ccre_annots[\"PLS\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4790 out of 5040 gene-boundary peaks are actually annotated as promoters *or* proximal enhancers\n",
    "(gene_region_annots[\"genes\"] * gene_region_annots[\"intergenic\"] * np.logical_or(ccre_annots[\"pELS\"], ccre_annots[\"PLS\"])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of those overlap an exon annotation as well, makes sense\n",
    "(gene_region_annots[\"genes\"] * gene_region_annots[\"intergenic\"] * gene_region_annots[\"exons\"] * ccre_annots[\"PLS\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35653e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of them overlap a UTR annotation (so are for coding genes)\n",
    "(gene_region_annots[\"genes\"] * gene_region_annots[\"intergenic\"] * gene_region_annots[\"utrs\"] * ccre_annots[\"PLS\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8372311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most annotated promoters (15419 / 16960, 91%) overlap with gene annotations also\n",
    "(gene_region_annots[\"genes\"] * ccre_annots[\"PLS\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many of each region do we have?\n",
    "[(k, sum(t)) for k, t in gene_region_annots.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48e12a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_stratify(metrics, ccre_annots, hk_annots, tct_annots, gene_region_annots,\n",
    "                  motif_filters, motif_keys_labels, metric_name, x_axis_0_to_1 = True,\n",
    "                  save_path=None):\n",
    "    \n",
    "    annots_to_labels = {\"PLS\" : \"Promoters\",\n",
    "                        \"pELS\" : \"Proximal\\nEnhancers\",\n",
    "                        \"dELS\" : \"Distal\\nEnhancers\",\n",
    "                        \"PLS_with_pELS\" : \"Promoters with\\nProximal Enhancers\",\n",
    "                        \"PLS_no_pELS\" : \"Promoters without\\nProximal Enhancers\"}\n",
    "    \n",
    "    regions_to_labels = {\"promoters\" : \"At TSS\",\n",
    "                        \"genes\" : \"Gene Body\",\n",
    "                        \"genes_not_TSS\" : \"Gene Body\",\n",
    "                        \"exons\" : \"Exon\",\n",
    "                        \"exons_not_TSS\" : \"Exon\",\n",
    "                        \"intergenic\" : \"Intergenic\",\n",
    "                        \"intergenic_not_TSS\" : \"Intergenic\",\n",
    "                        \"utrs\" : \"UTR\",\n",
    "                        \"utrs_not_TSS\" : \"UTR\",\n",
    "                        \"introns\" : \"Intron\",\n",
    "                        \"introns_not_TSS\" : \"Intron\",}\n",
    "    regions_to_plot = [\"promoters\", \"genes_not_TSS\", \"intergenic_not_TSS\",\n",
    "                       \"exons_not_TSS\", \"utrs_not_TSS\", \"introns_not_TSS\"]\n",
    "\n",
    "    annots_to_labels_hk =  {\"hk\" : \"Housekeeping\\nPromoters\",\n",
    "                             \"not-hk\" : \"Dev. Reg.\\nPromoters\"}\n",
    "\n",
    "    annots_to_labels_tct =  {\"tct\" : \"RP-TCT\\nPromoters\"}\n",
    "\n",
    "    annots_to_plot = [\"PLS_with_pELS\", \"PLS_no_pELS\", \"dELS\"]\n",
    "\n",
    "    \n",
    "    y_labels = []\n",
    "    \n",
    "    plt.figure(figsize=(0.8 * 1.15, 3.6 * 1.05), dpi=300)\n",
    "\n",
    "    plt.axvline(np.median(metrics), linestyle=\"dashed\", alpha=0.3, color=\"k\", linewidth=0.8)\n",
    "    \n",
    "    num_groups = 7\n",
    "    groupings = [0] + [1 + i for i in range(len(annots_to_plot))]\n",
    "    for i in range(len(motif_filters)):\n",
    "        groupings += [i + groupings[-1] + 1] * 2\n",
    "    groupings += [len(motif_filters) + len(annots_to_plot) + 1] * len(annots_to_labels_hk)\n",
    "    groupings += [len(motif_filters) + len(annots_to_plot) + 1] * len(annots_to_labels_tct)\n",
    "    groupings += [len(motif_filters) + len(annots_to_plot) + 2] * len(regions_to_labels)\n",
    "    assert max(groupings) == num_groups - 1, (num_groups, groupings)\n",
    "    \n",
    "    #color_list = [\"k\", \"#6A4C93\", \"#4267AC\", \"#52A675\", \"#FFCA3A\", \"#FF924C\", \"#FF596F\"]\n",
    "    color_list = [\"#999999\", \"#f94144\", \"#ffbc42\", \"#05668d\", \"#66A238\", \"#008552\", \"#005151\"]\n",
    "    dot_size=0.5\n",
    "    dot_alpha=0.05\n",
    "    \n",
    "    y_index = 0\n",
    "    y_labels.append(\"All Peaks\")\n",
    "    plot_scatter_and_boxplot(metrics, y_index, color=color_list[groupings[y_index]],\n",
    "                             dot_size=dot_size, dot_alpha=dot_alpha, white_dot_size=1)\n",
    "    y_index += 1\n",
    "    y_offset = 0.3\n",
    "    yticks = [0]\n",
    "    \n",
    "    for annot_name in annots_to_plot:\n",
    "        y_labels.append(annots_to_labels[annot_name])\n",
    "        yticks.append(y_index + y_offset)\n",
    "\n",
    "        plot_scatter_and_boxplot(metrics[ccre_annots[annot_name]],\n",
    "                                 y_index + y_offset,\n",
    "                                 color = color_list[groupings[y_index]],\n",
    "                                 dot_size=dot_size, dot_alpha=dot_alpha, white_dot_size=1)\n",
    "        y_index += 1\n",
    "    \n",
    "    y_offset += 0.3\n",
    "    \n",
    "    for motif in motif_filters.keys():\n",
    "        y_labels.append(\"Promoters\\nWith \" + motif)\n",
    "        yticks.append(y_index + y_offset)\n",
    "\n",
    "        plot_scatter_and_boxplot(metrics[ccre_annots[\"PLS\"] * motif_filters[motif]],\n",
    "                                 y_index + y_offset,\n",
    "                                 color = color_list[groupings[y_index]],\n",
    "                                 dot_size=dot_size, dot_alpha=dot_alpha, white_dot_size=1)\n",
    "        y_index += 1\n",
    "        \n",
    "        y_labels.append(\"Promoters\\nWithout \" + motif)\n",
    "        yticks.append(y_index + y_offset)\n",
    "\n",
    "        plot_scatter_and_boxplot(metrics[ccre_annots[\"PLS\"] * (~ motif_filters[motif])],\n",
    "                                 y_index + y_offset,\n",
    "                                 color = color_list[groupings[y_index]],\n",
    "                                 dot_size=dot_size, dot_alpha=dot_alpha, white_dot_size=1)\n",
    "        y_index += 1\n",
    "        \n",
    "    y_offset += 0.3\n",
    "    \n",
    "    for annot_name in annots_to_labels_hk.keys():\n",
    "        y_labels.append(annots_to_labels_hk[annot_name])\n",
    "        yticks.append(y_index + y_offset)\n",
    "        \n",
    "        if annot_name == \"hk\":\n",
    "            metrics_subset = metrics[ccre_annots[\"PLS\"] * hk_annots]\n",
    "        else:\n",
    "            metrics_subset = metrics[ccre_annots[\"PLS\"] * (~ hk_annots)]\n",
    "\n",
    "        plot_scatter_and_boxplot(metrics_subset, y_index + y_offset,\n",
    "                                 color = color_list[groupings[y_index]],\n",
    "                                 dot_size=dot_size, dot_alpha=dot_alpha, white_dot_size=1)\n",
    "        y_index += 1\n",
    "        \n",
    "        \n",
    "    for annot_name in annots_to_labels_tct.keys():\n",
    "        if annot_name == \"tct\":\n",
    "            y_labels.append(annots_to_labels_tct[annot_name])\n",
    "            yticks.append(y_index + y_offset)\n",
    "\n",
    "            plot_scatter_and_boxplot(metrics[ccre_annots[\"PLS\"] * tct_annots],\n",
    "                                     y_index + y_offset,\n",
    "                                     color = color_list[groupings[y_index]],\n",
    "                                     dot_size=dot_size, dot_alpha=dot_alpha, white_dot_size=1)\n",
    "            y_index += 1\n",
    "        \n",
    "    y_offset += 0.3\n",
    "        \n",
    "    for region_name in regions_to_plot:\n",
    "        y_labels.append(regions_to_labels[region_name])\n",
    "        yticks.append(y_index + y_offset)\n",
    "        \n",
    "        metrics_subset = metrics[gene_region_annots[region_name]]\n",
    "        plot_scatter_and_boxplot(metrics_subset, y_index + y_offset,\n",
    "                                 color = color_list[groupings[y_index]],\n",
    "                                 dot_size=dot_size, dot_alpha=dot_alpha, white_dot_size=1)\n",
    "        y_index += 1\n",
    "        \n",
    "        \n",
    "    plt.xlabel(metric_name, fontsize=6)\n",
    "    \n",
    "    # aesthetics\n",
    "    ax = plt.gca()\n",
    "    #ax.spines[[\"left\", \"bottom\"]].set_linewidth(1.2)\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_color(\"#333333\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False) \n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    plt.tick_params(\"y\", length=0, labelsize=4.5)\n",
    "    plt.tick_params(\"x\", length=2, labelsize=4.5, pad=2)\n",
    "    \n",
    "    if x_axis_0_to_1:\n",
    "        plt.xticks([0, 0.5, 1])\n",
    "    plt.yticks(yticks, y_labels)\n",
    "    \n",
    "    plt.ylim(plt.gca().get_ylim()[1] - 0.5, plt.gca().get_ylim()[0] + 0.5)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_stratify(jsds_pred_vs_obs, ccre_annots,\n",
    "              hk_annots, tct_annots, gene_region_annots,\n",
    "              motif_filters, motif_names, metric_name=\"JSD\", x_axis_0_to_1=False,\n",
    "              save_path = figures_dir + \"S1_stratified_jsd.png\")\n",
    "    \n",
    "plot_stratify(norm_jsds, ccre_annots,\n",
    "              hk_annots, tct_annots, gene_region_annots,\n",
    "              motif_filters, motif_names, metric_name=\"Normalized JSD\",\n",
    "              save_path = figures_dir + \"S1_stratified_norm_jsd.png\")\n",
    "\n",
    "plot_stratify(pearson_rs_pred_vs_obs, ccre_annots,\n",
    "              hk_annots, tct_annots, gene_region_annots,\n",
    "              motif_filters, motif_names, metric_name=\"Pearson Corr.\",\n",
    "              save_path = figures_dir + \"S1_stratified_norm_pearson.png\")\n",
    "\n",
    "plot_stratify(norm_pearson_rs, ccre_annots,\n",
    "              hk_annots, tct_annots, gene_region_annots,\n",
    "              motif_filters, motif_names, metric_name=\"Norm. Pearson Corr.\",\n",
    "              save_path = figures_dir + \"S1_stratified_norm_pearson.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_JSD_site_indexes = (norm_jsds > 0.9).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3d808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ax_pretty(ax, linewidth=1.2, ax_color = \"#333333\", ticklabelsize=8):\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_linewidth(linewidth)\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_color(ax_color)\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    ax.tick_params(length=2, labelsize=ticklabelsize)\n",
    "    \n",
    "\n",
    "def make_plots_for_outliers(outlier_indexes, true_profs, true_counts,\n",
    "                               peak_hit_counts, gene_region_annots, TSS_dists,\n",
    "                           save_path=None):\n",
    "    \n",
    "    # you have to manually change this if you change the threshold above. sorry\n",
    "    group_names = [\"All Peaks\", \"Peaks Where\\nNorm. JSD > 0.9\"]\n",
    "    \n",
    "    regions_to_labels = {\"promoters\" : \"At TSS\",\n",
    "                        \"genes\" : \"Gene Body\",\n",
    "                        \"genes_not_TSS\" : \"Gene Body\",\n",
    "                        \"exons\" : \"Exon\",\n",
    "                        \"exons_not_TSS\" : \"Exon\",\n",
    "                        \"intergenic\" : \"Intergenic\",\n",
    "                        \"intergenic_not_TSS\" : \"Intergenic\",\n",
    "                        \"utrs\" : \"UTR\",\n",
    "                        \"utrs_not_TSS\" : \"UTR\",\n",
    "                        \"introns\" : \"Intron\",\n",
    "                        \"introns_not_TSS\" : \"Intron\"}\n",
    "    regions_to_plot = [\"promoters\", \"intergenic_not_TSS\", \"genes_not_TSS\",\n",
    "                       \"introns_not_TSS\", \"exons_not_TSS\", \"utrs_not_TSS\"]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(6.2,2.7), dpi=300)\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.6)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Counts histogram\n",
    "    \n",
    "    log_all_true_counts = np.log10(true_counts.sum(axis=1) + 1)\n",
    "    log_outlier_true_counts = np.log10(true_counts[outlier_indexes].sum(axis=1) + 1)\n",
    "    \n",
    "    axes[0].hist(log_all_true_counts, alpha=0.8, density=True, color=\"gray\")\n",
    "    axes[0].hist(log_outlier_true_counts, alpha=0.7, density=True, color=\"salmon\")\n",
    "    \n",
    "    axes[0].set_xlabel(\"Reads\", fontsize=9)\n",
    "    axes[0].set_ylabel(\"Density\", fontsize=9)\n",
    "    \n",
    "    xticks = [2,4]\n",
    "    axes[0].set_xticks(xticks, [r'$10^{' + str(i) + r'}$' for i in xticks])\n",
    "    \n",
    "    # OI histogram\n",
    "    \n",
    "    ois = get_orientation_indexes(true_profs)\n",
    "    \n",
    "    axes[1].hist(ois,\n",
    "                 alpha=0.8, density=True, color=\"gray\")\n",
    "    axes[1].hist(ois[outlier_indexes],\n",
    "                 alpha=0.7, density=True, color=\"salmon\")\n",
    "    \n",
    "    axes[1].set_xlabel(\"Orientation Index\", fontsize=9)\n",
    "    axes[1].set_ylabel(\"Density\", fontsize=9)\n",
    "    \n",
    "    # Motif hits histogram\n",
    "    \n",
    "    motif_hits = peak_hit_counts.sum(axis=1)\n",
    "    axes[2].hist(motif_hits,\n",
    "             bins=range(14), alpha=0.8, density=True, color=\"gray\")\n",
    "    axes[2].hist(motif_hits[outlier_indexes],\n",
    "             bins=range(14), alpha=0.7, density=True, color=\"salmon\")\n",
    "    \n",
    "    axes[2].set_xlabel(\"Motif Hits\", fontsize=9)\n",
    "    axes[2].set_ylabel(\"Density\", fontsize=9)\n",
    "    \n",
    "    axes[2].set_xticks(range(0,14,3))\n",
    "    \n",
    "    # TSS distances histogram\n",
    "\n",
    "    stop_point = 25000\n",
    "    num_bins = int(np.ceil(stop_point / 2000))\n",
    "    axes[3].hist([min(d, stop_point) for d in TSS_dists if d is not None],\n",
    "             density=True, bins=num_bins,\n",
    "             alpha=0.8, color=\"gray\")\n",
    "    axes[3].hist([min(d, stop_point) for d in TSS_dists[outlier_indexes] if d is not None],\n",
    "             density=True, bins=num_bins,\n",
    "             alpha=0.7, color=\"salmon\")\n",
    "\n",
    "    axes[3].set_xlim(-500, stop_point + 500)\n",
    "    axes[3].set_xlabel(\"Distance (kb) to\\nNearest TSS\", fontsize=9)\n",
    "    axes[3].set_ylabel(\"Density\", fontsize=9)\n",
    "    axes[3].ticklabel_format(axis=\"y\", style=\"scientific\", scilimits=(0,0))\n",
    "    axes[3].yaxis.offsetText.set_fontsize(6)\n",
    "    \n",
    "    middle_tick = int(stop_point / 2000) * 1000\n",
    "    axes[3].set_xticks([0, middle_tick, stop_point],\n",
    "                       [\"0\", middle_tick // 1000, str(stop_point // 1000) + \"+\"])\n",
    "    \n",
    "    # Gene annotation regions double bar plot\n",
    "\n",
    "    fracs_overall = []\n",
    "    fracs_in_region = []\n",
    "    for region_name in regions_to_plot:\n",
    "        region_bools = gene_region_annots[region_name]\n",
    "        frac_overall = sum(region_bools) / len(region_bools)\n",
    "        frac_in_region = sum(region_bools[outlier_indexes]) / len(region_bools[outlier_indexes])\n",
    "        fracs_overall.append(frac_overall)\n",
    "        fracs_in_region.append(frac_in_region)\n",
    "\n",
    "    barplot_x_vals = np.arange(len(fracs_overall))\n",
    "    bar_width = 0.4\n",
    "    b1 = axes[4].bar(barplot_x_vals, fracs_overall,\n",
    "                 width=bar_width, label=group_names[0], color=\"gray\", alpha=0.8)\n",
    "    # Same thing, but offset the x.\n",
    "    b2 = axes[4].bar(barplot_x_vals + bar_width, fracs_in_region,\n",
    "                 width=bar_width, label=group_names[1], color=\"salmon\", alpha=0.7)\n",
    "\n",
    "    # x axis ticks need to be offset to go under center of two bars\n",
    "    axes[4].set_xticks(barplot_x_vals + bar_width / 2,\n",
    "                       labels=[regions_to_labels[region_name] for region_name in regions_to_plot],\n",
    "                       rotation=90, fontsize=6)\n",
    "    axes[4].set_ylabel(\"Frac. Peaks\", fontsize=9)\n",
    "    axes[4].set_yticks([0, 0.25, 0.5])\n",
    "\n",
    "    # will function as legend for all subplots\n",
    "    axes[4].legend(bbox_to_anchor=(1.3,1), loc=\"upper left\",\n",
    "               frameon=True, labelspacing=1, fontsize=8)\n",
    "    \n",
    "    \n",
    "    # cosmetics for each subplot\n",
    "    for axis in axes:\n",
    "        make_ax_pretty(axis)\n",
    "    \n",
    "    # disappear unused axis\n",
    "    axes[-1].remove()\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "make_plots_for_outliers(low_JSD_site_indexes, true_profs, true_counts,\n",
    "                           peak_hit_counts[\"profile\"], gene_region_annots, TSS_dists,\n",
    "                        save_path = figures_dir + \"S1_outliers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256c12d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(ois == 1), np.sum(ois[low_JSD_site_indexes] == 1))\n",
    "print(np.sum(ois[low_JSD_site_indexes] == 1) / np.sum(ois == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09ef202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(ois[low_JSD_site_indexes] == 1), np.sum(low_JSD_site_indexes))\n",
    "print(np.sum(ois[low_JSD_site_indexes] == 1) / np.sum(low_JSD_site_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84235568",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(low_JSD_site_indexes) / true_profs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb540c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in \"profiles\" of binarized mappability tracks\n",
    "\n",
    "umap_masks = extract_peaks(merged_config.genome_path,\n",
    "                           merged_config.chrom_sizes,\n",
    "                           merged_config.plus_bw_path,\n",
    "                           merged_config.minus_bw_path,\n",
    "                           merged_config.all_peak_path,\n",
    "                           mask_bw_path=merged_config.mask_bw_path,\n",
    "                           in_window=in_window,\n",
    "                           out_window=out_window,\n",
    "                           max_jitter=0, verbose=True)[-1][:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef25b8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_mappability_vs_performance(metrics, umap_masks, metric_name, save_path=None):\n",
    "    # what fraction of bases in the model output window are uniquely mappable?\n",
    "    umap_frac = umap_masks.mean(axis=-1)\n",
    "\n",
    "    # make boolean lists for whether each peak's mappability is within 3 bins\n",
    "    umap_all_mappable = umap_frac == 1  # 100% mappable\n",
    "    umap_mostly_mappable = (umap_frac < 1) * (umap_frac >= 0.7)  # between 70% and 100% mappable\n",
    "    umap_least_mappable = umap_frac < 0.7  # less than 70% mappable\n",
    "\n",
    "    plt.figure(figsize=(1.5, 1.5), dpi=300)\n",
    "    \n",
    "    y_labels = []\n",
    "    y_index = 0\n",
    "    y_labels.append(\"Fully\\nMappable\")\n",
    "    plot_scatter_and_boxplot(metrics[umap_all_mappable], y_index,\n",
    "                             color=\"tab:blue\", dot_alpha=0.05)\n",
    "    y_index += 1\n",
    "    \n",
    "    y_labels.append(\"70-100%\\nMappable\")\n",
    "    plot_scatter_and_boxplot(metrics[umap_mostly_mappable], y_index,\n",
    "                             color=\"tab:orange\", dot_alpha=0.05)\n",
    "    y_index += 1\n",
    "    \n",
    "    y_labels.append(\"< 70%\\nMappable\")\n",
    "    plot_scatter_and_boxplot(metrics[umap_least_mappable], y_index,\n",
    "                             color=\"tab:green\", dot_alpha=0.05)\n",
    "    y_index += 1\n",
    "\n",
    "    plt.xlabel(metric_name, fontsize=10)\n",
    "        \n",
    "    # aesthetics \n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_linewidth(1.2)\n",
    "    ax.spines[[\"left\", \"bottom\"]].set_color(\"#333333\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "\n",
    "    ax.tick_params(\"y\", length=0)\n",
    "    ax.tick_params(\"x\", length=2)\n",
    "    plt.xticks([0, 0.5, 1], fontsize=7)\n",
    "\n",
    "    plt.yticks(range(len(y_labels)), y_labels, fontsize = 8)\n",
    "    plt.ylim(plt.gca().get_ylim()[1], plt.gca().get_ylim()[0] - 0.1)\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_mappability_vs_performance(norm_jsds, umap_masks, metric_name=\"Normalized JSD\",\n",
    "                                   save_path = figures_dir + \"S1_mappability_norm_jsd.png\")\n",
    "\n",
    "plot_mappability_vs_performance(norm_pearson_rs, umap_masks, metric_name=\"Norm. Pearson Corr.\",\n",
    "                                   save_path = figures_dir + \"S1_mappability_norm_pearson.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd8c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:procap_A100] *",
   "language": "python",
   "name": "conda-env-procap_A100-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
